{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Large Language Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create a virtual environment**\n",
    "\n",
    "If you are working on a lab computer, check whether there already is a virtual environment in `/var/vsv306`. In a terminal do:\n",
    "```\n",
    "ls /var/csc306\n",
    "```\n",
    "If you see a folder named `csc306.venv`, someone has already created a virtual environment on this computer.\n",
    "\n",
    "If not, run:\n",
    "```\n",
    "python3 -m venv /var/csc306/csc306.venv\n",
    "```\n",
    "\n",
    "(If you are working on your own computer, you can put the virtual environment wherever you want. Replace `/var/csc306` accordingly.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activate virtual environment**\n",
    "\n",
    "```\n",
    "source /var/csc306/csc306.venv/bin/activate\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install libraries**\n",
    "```\n",
    "pip install ipykernel openai python-dotenv rich rank_bm25\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Select a kernel**\n",
    "\n",
    "To execute cells in this notebook, you need to connect to a Python kernel. You want to use the virtual environment you created. In VS Code type `Ctrl-shift-p` and then `Python: select interpreter`. That should bring up a drop down menu. Choose \"Enter interpreter path\" and then \"Browse your file system to find a Python interpreter\". Navigate to `/var/csc306/csc306.venv/bin/python`. \n",
    "\n",
    "Now click \"Select Kernel\" in the top right of your VS Code editor panel. Then choose \"Python environments\". Your virtual environment should be one of the options.\n",
    "\n",
    "Now, you should be able to run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hello Python!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Autoreload imported Python files when they change**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executing this cell will ensure that imported modules (.py files) will automatically\n",
    "# be reloaded when they change. (However, objects that were defined with the old\n",
    "# version of the class won't change.)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an OpenAI client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An OpenAI API key will be sent to you.\n",
    "\n",
    "Make an `.env` file in the same directory as this notebook, containing the following:\n",
    "```\n",
    "export OPENAI_API_KEY=[your API key]    # do not include the brackets here\n",
    "```\n",
    "Make sure others can't read this file:\n",
    "```\n",
    "chmod 600 .env\n",
    "```\n",
    "\n",
    "**Be sure to keep the key secret.  It gives access to a billable account.** If OpenAI finds it on the public web, they will invalidate it, and then no one (including you) can use this key to make requests anymore.\n",
    "\n",
    "Now you can execute the following to get an OpenAI client object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tracking import new_default_client, read_usage\n",
    "client = new_default_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That fetches your API key and calls `openai.OpenAI()` to make a new **client** object, whose job is to talk to the OpenAI **server** over HTTP.  (The `OpenAI` constructor has some optional arguments that configure these HTTP messages. However, the defaults should work fine for you.)\n",
    "\n",
    "That command also saved the new client in `tracking.default_client`, which is the client that the starter code will use by default whenever it needs to talk to the OpenAI server.  Thus, you should **rerun the above cell** to get a new client if you change the `default_model` in `tracking.py`, or if your API key in  `.env` ever changes, or its associated organization ever changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the model!\n",
    "\n",
    "You can now get answers from OpenAI models by calling methods of the `client` instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the function from class. Try it to make sure you can access the OpenAI API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete(client, s: str, model=\"gpt-3.5-turbo-0125\", *args, **kwargs):\n",
    "    response = client.chat.completions.create(messages=[{\"role\": \"user\", \"content\": s}],\n",
    "                                              model=model,\n",
    "                                              *args, **kwargs)\n",
    "    return [choice.message.content for choice in response.choices]\n",
    "\n",
    "complete(client, \"I went to the store and I bought apples, bananas, cherries, donuts, eggs\",\n",
    "         n=10, temperature=0.6, max_tokens=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute a function using instructions and few-shot prompting\n",
    "\n",
    "Let's try prompting the model with a sequence of multiple messages. In this case, we provide some instructions as well as few-shot prompting (actually just one-shot in this case).\n",
    "\n",
    "Instructions are in the `system` message. The few-shot prompting consists of example inputs (`user` messages) followed by their example outputs (`assistant` messages). Then we give our real input (the final `user` message), and hope that the LLM will continue the pattern by generating an analogous output (a new `assistant` message)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "response = client.chat.completions.create(messages=[{ \"role\": \"system\",      # instructions\n",
    "                                                      \"content\": \"Reverse the order of the words.\" },\n",
    "                                                    { \"role\": \"user\",        # input\n",
    "                                                      \"content\": \"Good things come to those who wait.\" },\n",
    "                                                    { \"role\": \"assistant\",   # output\n",
    "                                                      \"content\": \"Wait who those to come things good.\" },\n",
    "                                                    { \"role\": \"user\",        # input\n",
    "                                                      \"content\": \"Colorless green ideas sleep furiously.\" }],\n",
    "                                          model=\"gpt-4o-mini\", temperature=0)\n",
    "#rich.print(response)\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By modifying this call, can you get it to produce different versions of the output? Some possible behaviors you could try to arrange:\n",
    "\n",
    "* specific other way of formatting the output, e.g., wait, who, those, to, come, things, good\n",
    "* match the input's way of formatting the output (same use of capitalization, puncutation, commas)\n",
    "* reverse the phrases rather than reversing the words, e.g., To those who wait come good things.\n",
    "\n",
    "You can try playing with the number, the content, and the order of few-shot examples, and changing or removing the instructions.\n",
    "\n",
    "What happens if the examples conflict with the instructions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check your usage so far\n",
    "\n",
    "Please be careful not to write loops that use lots and lots of tokens. That will cost us money, and could hit the per-day usage limit that is shared by the whole class.\n",
    "\n",
    "Execute the cell below whenever you want to see your cost so far. Or, just open `usage_openai.json` as a tab in your IDE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_usage()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogues and dialogue agents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this assignment is to create a good \"argubot\" that will talk to people about controversial topics and broaden their minds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A first argubot (Airhead)\n",
    "\n",
    "You can have a conversation right now with a really bad argubot named Airhead. Try asking it about climate change! When you're done, reply with an empty string.\n",
    "\n",
    "(The `converse()` method calls Python's `input()` function, which will prompt you for input at the command-line or by popping up a box in your IDE. In VS Code, the input box appears at the top edge of the window.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argubots\n",
    "d = argubots.airhead.converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bot (short for \"robot\") is a system that acts autonomously. That corresponds to the AI notion of an agent — a system that uses some policy to choose actions to take.\n",
    "\n",
    "The airhead agent above (defined in `argubots.py`) uses a particularly simple policy.\n",
    "It is an instance of a simple Agent subclass called `ConstantAgent` (defined in `agents.py`).\n",
    "\n",
    "The result of talking to airhead is a Dialogue object (defined in dialogue.py). Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich.print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each turn of this dialogue is just a tiny dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An LLM argubot (Alice)\n",
    "\n",
    "In other CS courses, you may have encountered \"conversations\" between characters named Alice and Bob.\n",
    "\n",
    "Let's try talking to the Alice of this homework, who is a much stronger baseline than Airhead. Your job in this assignment is to improve upon Alice. We'll meet Bob later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call with argument d if you want to append to the previous conversation\n",
    "alicechat = argubots.alice.converse()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have guessed, `alice` is powered by a prompted LLM. You can find the specific prompt in `argubots.py`.\n",
    "\n",
    "So, while `agents.py` provides the core functionality for `Agent` objects, the argubot agents like `alice` -- and the ones that you will write! -- go into `argubots.py` instead. This is just to keep the files small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating human characters (Bob & friends)\n",
    "\n",
    "You'll talk to your own argubots to get a qualitative feeling for their strengths and weaknesses.\n",
    "But can you really be sure you're making progress? For that, a quantitative measure can be helpful.\n",
    "\n",
    "Ultimately, you should test an argubot like Alice by having it argue with many real humans — not just you — and using some rubric to score the resulting dialogues. But that would be slow and complicated to arrange.\n",
    "\n",
    "So, meet Bob! He's just a simulated human. You won't edit him: he is part of the development set. Here is some information about him (from `characters.py`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import characters\n",
    "rich.print(characters.bob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can't talk directly to `characters.bob` because that's just a data object. However, you can construct a simple agent that uses that data (plus a few more instructions) to prompt an LLM.\n",
    "\n",
    "(Which LLM does it prompt? The `CharacterAgent` constructor (defined in `agents.py`) defaults to gpt-4o-mini as specified in tracking.py. But you can override that using keyword arguments.)\n",
    "\n",
    "Try talking to Bob about climate change, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agents import CharacterAgent\n",
    "# actually, agents.bob is already defined this way\n",
    "bob = CharacterAgent(characters.bob)\n",
    "# returns a dialogue, but we've already seen it so we don't want to print it again\n",
    "bob.converse()\n",
    "# don't print anything for this notebook cell\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, a proper user study can't just be conducted with one human user.\n",
    "\n",
    "So, meet our bevy of beautiful Bobs! (They're not actually all named Bob — we continued on in the alphabet.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import agents\n",
    "agents.devset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agents.cara.converse()\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see the underlying character data here in the notebook. Your argubot will have to deal with all of these topics and styles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich.print(characters.devset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulating conversation\n",
    "\n",
    "We can make Alice and Bob chat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dialogue import Dialogue\n",
    "d = Dialogue()                                              # empty dialogue\n",
    "d = d.add('Alice', \"Do you think it's okay to eat meat?\")   # add first turn\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = agents.bob.respond(d)\n",
    "d = argubots.alice.respond(d)\n",
    "rich.print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = agents.bob.respond(d)\n",
    "d = argubots.alice.respond(d)\n",
    "rich.print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anyway, let's see what happens when Alice and Bob talk for a while..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from simulate import simulated_dialogue\n",
    "d = simulated_dialogue(argubots.alice, agents.bob, 8)\n",
    "rich.print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes this kind of conversation seems to stall out, with Bob in particular repeating himself a lot. Alice doesn't seem to have a good strategy for getting him to open up. Maybe you can do a better job talking to Bob, and that will give you some ideas about how to improve Alice?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your name, pulled from an earlier dialogue\n",
    "myname = alicechat[0]['speaker']\n",
    "# reuse the same first two turns, then type your own lines!\n",
    "agents.bob.converse(d[0:2].rename('Alice', myname))\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also try talking to the other characters and having Alice (or Airhead) talk to them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "❓❓❓ <b>Task 1<b>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define an additional character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from characters import Character\n",
    "\n",
    "# See characters.py for how to use the Character class.\n",
    "# Add the definition of your character here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** Please don't change the dev set — the characters we just loaded must stay the same. Your job in this homework is to improve the argubot (or at least try). And that means improving it according to a fixed and stable evaluation measure."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
